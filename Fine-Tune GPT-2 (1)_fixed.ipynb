{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRQHluT6t3vEWX/782FYDb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Loading Dataset\n"
      ],
      "metadata": {
        "id": "P06x2I9BiIhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://huggingface.co/datasets/stevez80/Sci-Fi-Books-gutenberg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2oOvcVU7M5J",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712367758,
          "user_tz": -360,
          "elapsed": 12334,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "ff1f9659-104b-407c-ec39-3a8105e40a71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sci-Fi-Books-gutenberg'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 4.11 KiB | 842.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Sci-Fi-Books-gutenberg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdUPCM7x7MQS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712367797,
          "user_tz": -360,
          "elapsed": 32,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "eadec42b-4651-4113-e5fd-7e2cc95eee2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Sci-Fi-Books-gutenberg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"/content/Sci-Fi-Books-gutenberg/sci-fi-books.csv\")\n",
        "\n",
        "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Split the dataset\n",
        "dataset = dataset.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "Bp9Dc_mVt07C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712387205,
          "user_tz": -360,
          "elapsed": 19406,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Tokenize Data"
      ],
      "metadata": {
        "id": "v3lvlmy5v8KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "\n",
        "tokenized = dataset.map(tokenize_function, batched=True, remove_columns=[\"id\", \"title\", \"author\", \"text\"])\n",
        "\n",
        "\n",
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "5ac7fa35935a4cb4ac02f8124a1c144e",
            "ae50eada9f0444e4925a8ff1285497df",
            "c751c6fa46554ae294412c62adab1117",
            "b5004008a61742cc80a5acc70c47ee31",
            "cc84cbbdcac24eacac3bd209e48e33e9",
            "8b656b65254c4e14aa518bd13b76b182",
            "8fc99c2c661c4b6399d91203acfbb242",
            "284d858502184594b80a415051486064",
            "8987b0c0994a45e7b0a65a03e5122f5a",
            "3475e5fd36bc4d9296f5a057b1b46198",
            "8fbcf0ab72e24007b43a07c7be36e928",
            "aacd379d71c24222bc2f2f0264b05887",
            "5af7c5aa81414458b583debca17779ba",
            "596616b779a34ac68a84c724fe70f3e2",
            "64ae742f0c774ef79fe073b135fca8ec",
            "bec0487be4e547d9993dea8e91ebd328",
            "07114f04a810451c8b6ce96e7a974858",
            "1f3d8d43cb554377a6fa2e1bd4f12efd",
            "ac95a3dafe774b9daf71aa1189ec6316",
            "d8f7cbcb986442f0bc80228e48226584",
            "099af3eeea8f47e088f01a38dcb240af",
            "7151a44793bc446590166b6a7692dfc1",
            "39e817d195b34cce84229f0e6e781d32",
            "ff3d52220a044abd99014c45e4896162",
            "cbb6b4a039c341e1be6d4b2094e016b8",
            "507140cfa1c043cf867bf607f859ab83",
            "2522f3d6221d42668cc6ca8e1626c2e6",
            "3e638ccd34654ea3a8357f3989f2d08d",
            "2d02609358034e15b0c8b4ebd473338c",
            "8abe54ece3b94c3a8f8d0c327e6d6d44",
            "0a00a57564a741f8864937a1d5fdcb0d",
            "805b385b0d0e4a06b49f00b44ed8cb68",
            "c811ebe9a1fe4260ad9da04197dd1225",
            "e60d5409ef0547a383186183ae3a865b",
            "335860e0539b41fba6090f533bfc2432",
            "a1b74e966d504106b3b3d161027ac628",
            "2eb9478a020848348fd2b83baae711f4",
            "a8ec202d5d704211b85bea12370da2f4",
            "831c4de28b4e42e4b40d98f3c3fa19c4",
            "c504d034ec3146f4a5126226cc5153b3",
            "ff91ed532a104da09226f4e03978f9fb",
            "893667b3cb494f99873009d174101abb",
            "4da843a585f249fb982e3262ad7c422a",
            "2cfac9005b364e499fda46170043e3b4",
            "fa49a1140eed4e569b3d12ea687312d4",
            "7c7040518a6f4688a62095efe8718579",
            "6c67ec88247347b495f00187f02533c2",
            "bcba31c4cf5247e1a4c38c0a48f016cd",
            "5ba74b3a120141c98e3177172691c402",
            "343e1f954466430181970c4e6a08fa38",
            "026b58c02c7a4f21b3a13952bdba9f72",
            "ac923ef2c32f4343ac471937371e268e",
            "113a00a5e7514fe4839128aa45413055",
            "99b4035d31304481adfc6971656fe96d",
            "9fb5b02a94cc49eb9e8618e94a668c67",
            "a3278568a8b54cf5bc16c52a51aa4e56",
            "0dd801cbb2884fb1865f5c1c4a153544",
            "d3a971768b584b29914b79bbe68d4173",
            "c7a79de66370433899e61d53705e33a1",
            "cb095a2ac40b46eaa09e0b46725732a9",
            "38f040637d3d46cebe2bf0ab1a55488a",
            "5d672ff96b524b6989097ea0c08cf538",
            "37efad7405884592ba4a342d210091d5",
            "d5718bab47864541aaace37b75ae7d56",
            "062f09b45ea9466d9550a50a6aa2c224",
            "a6c8ec577c854b3d9b3a4d3e94b6a9c1",
            "affdd11a54694774bf9afdc3033ff331",
            "75f818aeb58742578f5c270ab1a4918e",
            "b7ca46a9a1d640df92d1d86081ff4da1",
            "d1d3901b0c9d4e0f9138f6bd22daf6e7",
            "06d65ea8386b49e49742398a9fd36c97",
            "8bc56212a1f64eaba02adc9a22d49e92",
            "6d5e511e2fb740588151b1611ba159d3",
            "c4f7290ced104583801968e61a442f01",
            "8679a2e4a9504c28a65a025a8a1761dc",
            "0a6be7ace062405d839d98a2c78a7955",
            "f1314ecd5eaf4e858b1eed0674d4645c"
          ]
        },
        "id": "IJwJlus0v9mK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712824958,
          "user_tz": -360,
          "elapsed": 437764,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "3c0162a8-4b17-4805-eaf8-1c4debcf7e79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac7fa35935a4cb4ac02f8124a1c144e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aacd379d71c24222bc2f2f0264b05887"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39e817d195b34cce84229f0e6e781d32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e60d5409ef0547a383186183ae3a865b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa49a1140eed4e569b3d12ea687312d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2683 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3278568a8b54cf5bc16c52a51aa4e56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/671 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "affdd11a54694774bf9afdc3033ff331"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 2683\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 671\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Load Quantized GPT-2 Medium"
      ],
      "metadata": {
        "id": "Ott3GnSGw1yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"gpt2-medium\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fe6c71e28463437181c1bfc0a6162f23",
            "888060cb976e46d2ac9aa8cfc3e185ad",
            "95e1b2171b72404aa9ed42e9daec8769",
            "edc779275cbf4c38af4990ee73bdef55",
            "c92a3daa33fd4660b8911bc8291768cb",
            "64e4300c938d413caa05570710d50917",
            "b6fc71b4e21e475d9d1344cbfd205989",
            "128d1d499616483d94741d7817b93ed8",
            "6cea5e4049b941ac9c0d3f824e99113a",
            "89ba3502b68e4fc591cea374e094e600",
            "dbd01b189d6f45359b89f7e71d9b93c8",
            "f11ebbb94a87438483cd1952871fa441",
            "a99bca7ff9914349922a89426e234979",
            "3c5d42004f5a4d4d86cfe076ef87fd7f",
            "82960038722d44248d6d5f2f3cc1edce",
            "a3f5f5769e484e02992211e2b5495fd6",
            "1e8793d85a9d4143a02c37c180086973",
            "34698c43327e4523ad978a30f2e4dd47",
            "1dee1938c7234e6282421ff43c4cdfda",
            "ba7e3e047784409c834336be31d5b1fa",
            "3ce53824752b4e709e0a90d0b57a51ef",
            "a5ee5f47be98486daec0490d109ad83e"
          ]
        },
        "id": "Go1quW-Uze8D",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712921025,
          "user_tz": -360,
          "elapsed": 96071,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "dc948b38-7325-437a-a92f-24c490e721d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe6c71e28463437181c1bfc0a6162f23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f11ebbb94a87438483cd1952871fa441"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#    LoRA with PEFT"
      ],
      "metadata": {
        "id": "rN6btyIJ0nw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.0\n",
        "\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEDvPvPm0pE7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712921551,
          "user_tz": -360,
          "elapsed": 516,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "5119581a-4e5c-440d-d98e-1be7f9c8c4f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4,325,376 || all params: 359,148,544 || trainable%: 1.2043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Training Setup"
      ],
      "metadata": {
        "id": "YtEBFMoT3JAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./content\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "wKQQaOOJ3KjL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753712922866,
          "user_tz": -360,
          "elapsed": 1313,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training"
      ],
      "metadata": {
        "id": "2X6_DUuT54mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "5z-_9HwZ584r",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753713739395,
          "user_tz": -360,
          "elapsed": 816531,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "1788286e-6a7f-4cc1-d9e2-924ee5d139a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-3691388255.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5366' max='5366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5366/5366 13:34, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.655400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.506600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.479900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.444300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.437200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.423600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.410800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.413000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.398400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5366, training_loss=0.4568673474016449, metrics={'train_runtime': 816.0208, 'train_samples_per_second': 6.576, 'train_steps_per_second': 6.576, 'total_flos': 5054708947353600.0, 'train_loss': 0.4568673474016449, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7134e1f2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753713739400,
          "user_tz": -360,
          "elapsed": 7,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate on the test/validation set"
      ],
      "metadata": {
        "id": "OLvSHjyrpZp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Load model (if not already in memory)\n",
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    eval_dataset=tokenized[\"test\"]\n",
        ")\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Evaluation Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "8o1GXvazplnw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753713774541,
          "user_tz": -360,
          "elapsed": 35133,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "550962db-c4d0-44e7-c657-df38c0a078a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-1141100856.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [84/84 00:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics: {'eval_model_preparation_time': 0.0039, 'eval_runtime': 29.4894, 'eval_samples_per_second': 22.754, 'eval_steps_per_second': 2.848}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Save the fine-tuned model"
      ],
      "metadata": {
        "id": "TrxWZL5GpulS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./finetuned-gpt2-medium\")\n",
        "tokenizer.save_pretrained(\"./finetuned-gpt2-medium\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N35OSANppwcI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753713887226,
          "user_tz": -360,
          "elapsed": 112665,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "c9e787a9-b910-486b-f7ec-1cd4f8ea22ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned-gpt2-medium/tokenizer_config.json',\n",
              " './finetuned-gpt2-medium/special_tokens_map.json',\n",
              " './finetuned-gpt2-medium/vocab.json',\n",
              " './finetuned-gpt2-medium/merges.txt',\n",
              " './finetuned-gpt2-medium/added_tokens.json',\n",
              " './finetuned-gpt2-medium/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Inference"
      ],
      "metadata": {
        "id": "8jqxbGInqBjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./finetuned-gpt2-medium\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./finetuned-gpt2-medium\")\n",
        "from transformers import pipeline\n",
        "\n",
        "# Use text generation pipeline\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Generate text\n",
        "prompt = \"In a distant galaxy, a lady\"\n",
        "outputs = generator(prompt, max_length=100, num_return_sequences=1, temperature=0.8)\n",
        "\n",
        "print(outputs[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFSk06jzp9lp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1753713894065,
          "user_tz": -360,
          "elapsed": 6837,
          "user": {
            "displayName": "hulu world",
            "userId": "05131870956520847838"
          }
        },
        "outputId": "570c360f-9b5c-4af3-a5c4-58cbe88c1789"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a distant galaxy, a lady, the daughter of a prince, is called to the palace in an attempt to bring her husband back to civilization. Written by David P. Williams <davidp@lubris.com>\n"
          ]
        }
      ]
    }
  ]
}